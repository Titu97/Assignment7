{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "Tensorflow: 1.2.1\n",
      "Init with stored values from ../model/snapshot-32\n",
      "INFO:tensorflow:Restoring parameters from ../model/snapshot-32\n",
      "Recognized: \"summation\"\n",
      "Recognized: \"Love\"\n",
      "Recognized: \"ors\"\n",
      "Recognized: \"NoTtTAG\"\n",
      "Recognized: \"pownIoed\"\n",
      "Recognized: \"napoa\"\n",
      "Recognized: \"Shamimitne\"\n",
      "Recognized: \"farcacetamol\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import cv2\n",
    "import editdistance\n",
    "from DataLoader import DataLoader, Batch\n",
    "from Model import Model, DecoderType\n",
    "from SamplePreprocessor import preprocess\n",
    "import easydict\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "class FilePaths:\n",
    "\t\"filenames and paths to data\"\n",
    "\tfnCharList = '../model/charList.txt'\n",
    "\tfnAccuracy = '../model/accuracy.txt'\n",
    "\tfnTrain = '../data/'\n",
    "\tfnInfer = '../data/test.png'\n",
    "\tfnCorpus = '../data/corpus.txt'\n",
    "\n",
    "\n",
    "def train(model, loader):\n",
    "\t\"train NN\"\n",
    "\tepoch = 0 # number of training epochs since start\n",
    "\tbestCharErrorRate = float('inf') # best valdiation character error rate\n",
    "\tnoImprovementSince = 0 # number of epochs no improvement of character error rate occured\n",
    "\tearlyStopping = 5 # stop training after this number of epochs without improvement\n",
    "\twhile True:\n",
    "\t\tepoch += 1\n",
    "\t\tprint('Epoch:', epoch)\n",
    "\n",
    "\t\t# train\n",
    "\t\tprint('Train NN')\n",
    "\t\tloader.trainSet()\n",
    "\t\twhile loader.hasNext():\n",
    "\t\t\titerInfo = loader.getIteratorInfo()\n",
    "\t\t\tbatch = loader.getNext()\n",
    "\t\t\tloss = model.trainBatch(batch)\n",
    "\t\t\tprint('Batch:', iterInfo[0],'/', iterInfo[1], 'Loss:', loss)\n",
    "\n",
    "\t\t# validate\n",
    "\t\tcharErrorRate = validate(model, loader)\n",
    "\t\t\n",
    "\t\t# if best validation accuracy so far, save model parameters\n",
    "\t\tif charErrorRate < bestCharErrorRate:\n",
    "\t\t\tprint('Character error rate improved, save model')\n",
    "\t\t\tbestCharErrorRate = charErrorRate\n",
    "\t\t\tnoImprovementSince = 0\n",
    "\t\t\tmodel.save()\n",
    "\t\t\topen(FilePaths.fnAccuracy, 'w').write('Validation character error rate of saved model: %f%%' % (charErrorRate*100.0))\n",
    "\t\telse:\n",
    "\t\t\tprint('Character error rate not improved')\n",
    "\t\t\tnoImprovementSince += 1\n",
    "\n",
    "\t\t# stop training if no more improvement in the last x epochs\n",
    "\t\tif noImprovementSince >= earlyStopping:\n",
    "\t\t\tprint('No more improvement since %d epochs. Training stopped.' % earlyStopping)\n",
    "\t\t\tbreak\n",
    "\n",
    "\n",
    "def validate(model, loader):\n",
    "\t\"validate NN\"\n",
    "\tprint('Validate NN')\n",
    "\tloader.validationSet()\n",
    "\tnumCharErr = 0\n",
    "\tnumCharTotal = 0\n",
    "\tnumWordOK = 0\n",
    "\tnumWordTotal = 0\n",
    "\twhile loader.hasNext():\n",
    "\t\titerInfo = loader.getIteratorInfo()\n",
    "\t\tprint('Batch:', iterInfo[0],'/', iterInfo[1])\n",
    "\t\tbatch = loader.getNext()\n",
    "\t\trecognized = model.inferBatch(batch)\n",
    "\t\t\n",
    "\t\tprint('Ground truth -> Recognized')\t\n",
    "\t\tfor i in range(len(recognized)):\n",
    "\t\t\tnumWordOK += 1 if batch.gtTexts[i] == recognized[i] else 0\n",
    "\t\t\tnumWordTotal += 1\n",
    "\t\t\tdist = editdistance.eval(recognized[i], batch.gtTexts[i])\n",
    "\t\t\tnumCharErr += dist\n",
    "\t\t\tnumCharTotal += len(batch.gtTexts[i])\n",
    "\t\t\tprint('[OK]' if dist==0 else '[ERR:%d]' % dist,'\"' + batch.gtTexts[i] + '\"', '->', '\"' + recognized[i] + '\"')\n",
    "\t\n",
    "\t# print validation result\n",
    "\tcharErrorRate = numCharErr / numCharTotal\n",
    "\twordAccuracy = numWordOK / numWordTotal\n",
    "\tprint('Character error rate: %f%%. Word accuracy: %f%%.' % (charErrorRate*100.0, wordAccuracy*100.0))\n",
    "\treturn charErrorRate\n",
    "\n",
    "\n",
    "def infer(model, fnImg):\n",
    "\t\"recognize text in image provided by file path\"\n",
    "\tos.chdir('C:\\\\Users\\\\user\\\\Desktop\\\\t') \n",
    "\tfor f in os.listdir('.'):        \n",
    "\t\ttemp=np.asarray(Image.open(f))\n",
    "\n",
    "\t\ttemp= cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
    "\t\timg = preprocess(temp, Model.imgSize)        \n",
    "\t\tbatch = Batch(None, [img] * Model.batchSize) # fill all batch elements with same input image\n",
    "\t\trecognized = model.inferBatch(batch) # recognize text\n",
    "\t\tprint('Recognized:', '\"' + recognized[0] + '\"') # all batch elements hold same result\n",
    " \n",
    "\n",
    "\n",
    "def main():\n",
    "\t\"main function\"\n",
    "\t# optional command line args\n",
    " \n",
    "\targs=easydict.EasyDict({\n",
    "          \"train\":0,\n",
    "          \"validate\":0,\n",
    "          \"beamsearch\":0,\n",
    "          \"wordbeamsearch\":0\n",
    "\t})\n",
    "    \n",
    "\tdecoderType = DecoderType.BestPath\n",
    "\tif args.beamsearch:\n",
    "\t\tdecoderType = DecoderType.BeamSearch\n",
    "\telif args.wordbeamsearch:\n",
    "\t\tdecoderType = DecoderType.WordBeamSearch\n",
    "\n",
    "\t# train or validate on IAM dataset\t\n",
    "\tif args.train or args.validate:\n",
    "\t\t# load training data, create TF model\n",
    "\t\tloader = DataLoader(FilePaths.fnTrain, Model.batchSize, Model.imgSize, Model.maxTextLen)\n",
    "\n",
    "\t\t# save characters of model for inference mode\n",
    "\t\topen(FilePaths.fnCharList, 'w').write(str().join(loader.charList))\n",
    "\t\t\n",
    "\t\t# save words contained in dataset into file\n",
    "\t\topen(FilePaths.fnCorpus, 'w').write(str(' ').join(loader.trainWords + loader.validationWords))\n",
    "\n",
    "\t\t# execute training or validation\n",
    "\t\tif args.train:\n",
    "\t\t\tmodel = Model(loader.charList, decoderType)\n",
    "\t\t\ttrain(model, loader)\n",
    "\t\telif args.validate:\n",
    "\t\t\tmodel = Model(loader.charList, decoderType, mustRestore=True)\n",
    "\t\t\tvalidate(model, loader)\n",
    "\n",
    "\t# infer text on test image\n",
    "\telse:\n",
    "\t\t#print(open(FilePaths.fnAccuracy).read())\n",
    "\t\tmodel = Model(open(FilePaths.fnCharList).read(), decoderType, mustRestore=True)\n",
    "\t\tinfer(model, FilePaths.fnInfer)\n",
    " \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\tmain()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
